# 机器学习系列笔记

## 前言

这个系列，希望用相对容易理解的方式，介绍机器学习的发展的历程、基本概念、常见算法。

这些内容，有一些或许在曾经非常有风光，但是如今已经不再流行；也有一些是曾经被认为已经没有前途，但是现在非常流行的。

对于机器学习，很多人可能一上来就想到比如说深度学习、神经网络等等，甚至认为现在对于机器学习的研究也就是各种神经网络的使用，CNN（卷积神经网络）、RNN（循环神经网络）、LSTM（长短期记忆网络）等等；但是实际上，机器学习的历史远远不止这些，而且这些算法也并不是最早的机器学习算法。

此外，由于当前很多甚至是业内的机器学习从业者，也会误入一个陷阱，认为机器学习只需要一堆`import`然后call APIs即可，堆叠试验各种神经网络，试图“大力出奇迹”。对于许多问题有些许的认知，但是由于不懂得原理，导致真正遇到问题的时候除了试错性质的调参之外，能力很有限。

至于为什么一些已经认为是过时的算法，比如决策树、SVM等等，还要被拿来解释和学习，是因为这些算法的原理和思想，对于理解机器学习的基本概念和原理非常重要。而且，这些算法的思想，也是很多现在流行的算法的基础。比如，SVM的思想，被很多深度学习的算法所借鉴，用在了包括激活函数、优化算法等等方面。

机器学习，站在一个很宏观的视野看待，就是以下的几个部分：

- 数据
- 模型
- 算法
- 评估

而绝大多数的相关的资料，和绝大多数的关注都在于模型和算法。这部分本文姑且视为一个黑箱；而很多时候决定了一个机器学习效果的，还有数据的质量、数据的处理，以及对于结果的处理和评估。

在大模型时代，可能接下来随着算力的发展和各种工具的不断成熟，模型和算法的研究日渐专业，而越来越远离绝大多数的从业者。大家可能更加关注的是，如何寻找高质量的数据，如何更好地处理数据，如何给模型正确的评估结果的方式，以便更好地调整模型。放在今天，数据的输入就好比优化过 Prompt 的文本输入给 LLM，我们无以研究 LLM 内部是如何处理这些输入、发生了什么反应，但是他最终呈现给大家的就是一个输出；而这份输出，其质量如何、应该如何修订这个输出使得效果更好，就反而是绝大多数从业者乃至用户所关心的。

## 目录

- [贝叶斯分类器](./Bayes-classifier.md)
- [决策树](./Decision-tree.md)
- [支持向量机](./SVM.md)
- [K-近邻算法](./KNN.md)
- [回归](./Regression.md)
- [聚类](./Clustering.md)
- [降维](./Dimensionality-reduction.md)
- [集成学习](./Ensemble-learning.md)
- [深度学习](./Deep-learning.md)
- [数据处理](./Data-processing.md)
- [特征提取](./Feature-extraction.md)
- [模型评估](./Model-evaluation.md)

（未完待续）