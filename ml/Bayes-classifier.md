# 贝叶斯分类器

## 贝叶斯定理

$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
$$

其中，$P(A|B)$是在给定B的情况下A的概率（后验概率，Posterior Probability），$P(B|A)$是在给定A的情况下B的概率（条件概率，Conditional Probability；或者称为似然度，Likelihood），$P(A)$是A的概率（先验概率，Prior Probability），$P(B)$是B的概率。

对于上述公式，将其更一般化，可以得到：

$$
P(c_i|x) = \frac{P(x|c_i)P(c_i)}{\sum_{j=1}^{n}P(x|c_j)P(c_j)}
$$

其中，类条件概率（Class conditional probability）$P(x|c_i)$是指在类别$c_i$下样本$x$的概率，先验概率$P(c_i)$是指类别$c_i$的概率，后验概率$P(c_i|x)$是指在给定样本$x$的情况下类别$c_i$的概率。

可以得到，对于一个二分类问题，比如存在$A$和$A'$两个类别，那么对于一个样本$B$，可以得到：

$$
P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A')P(A')}
$$

## 贝叶斯分类器

### 基于最小错误率的贝叶斯决策

简单来说就是，对于一个二分类问题，先计算出先验概率$P(\omega)$和$P(\omega')$。那么，对于一个样本$x$，计算出$P(x|\omega)$和$P(x|\omega')$，然后计算出$P(\omega|x)$和$P(\omega'|x)$，最后比较$P(\omega|x)$和$P(\omega'|x)$，选择概率大的那个类别。

从这个过程可以看出来，这个决策基于的是观测到的条件概率密度，以及先验概率。这个过程是基于最小错误率的贝叶斯决策。

这个模型实际上是一个理论模型，因为实际上，$P(x|\omega)$和$P(x|\omega')$是难以得到的，甚至先验概率的真实值也很难准确获得，因此这些值需要通过一些方法来估计。

### 最大似然估计

实际上对于贝叶斯公式的分子，$P(x|c_i)P(c_i)$，可以通过最大似然估计来估计。

对于$P(x|c_i)$，可以通过样本集合$D$来估计，即：

$$
P(D_c:\theta_c) = \prod_{x \in D_c}P(x|\theta_c)
$$

这个式子实际上就是一个乘法原理，将所有样本的概率密度乘起来，得到的就是这个样本集合的概率密度。

对于上面那个式子，取对数，可以得到：

$$
\log P(D_c:\theta_c) = \sum_{x \in D_c}\log P(x|\theta_c)
$$

然后

$$
\theta_c = \arg \max_{\theta_c}\log P(D_c:\theta_c)
$$

这个过程就是最大似然估计。

### 朴素贝叶斯分类器

一个假设，即特征之间是相互独立的，因此可以相乘。

$$
h_{nb}(x) = \arg \max_{c_i}P(c_i)\prod_{j=1}^{n}P(x_j|c_i)
$$

先验概率$P(c_i)$可以通过样本集合$D$来估计，即：

$$
P(c_i) = \frac{|D_{c_i}|}{|D|}
$$

其中，$|D_{c_i}|$是类别$c_i$的样本数量，$|D|$是样本总数。

对于几个特征，可以通过下面的公式来估计：

- 对于连续特征，可以通过正态分布来估计，即：

$$
P(x_j|c_i) = \frac{1}{\sqrt{2\pi}\sigma_{c_i,j}}\exp(-\frac{(x_j-\mu_{c_i,j})^2}{2\sigma_{c_i,j}^2})
$$

其中，$\mu_{c_i,j}$是类别$c_i$下特征$j$的均值，$\sigma_{c_i,j}$是类别$c_i$下特征$j$的标准差。

- 对于离散特征，可以通过多项分布来估计，即：

$$
P(x_j|c_i) = \frac{N_{c_i,j}+1}{N_{c_i}+m}
$$

其中，$N_{c_i,j}$是类别$c_i$下特征$j$的样本数量，$N_{c_i}$是类别$c_i$的样本数量，$m$是特征$j$的取值数量。

## 贝叶斯分类器的扩展

### 基于最小风险的贝叶斯决策

对于一个二分类问题，可以定义一个损失$\lambda_{ij}$，表示将类别$i$误判为类别$j$的损失。那么，对于一个样本$x$，可以计算出$P(\omega|x)$和$P(\omega'|x)$，然后计算出$R(\omega|x)$和$R(\omega'|x)$，最后比较$R(\omega|x)$和$R(\omega'|x)$，选择损失小的那个类别。

一个具体的例子，对于比如说诊断疾病，由于疾病的发病率一般不高，所以如果使用传统的方法，那么可以直接判断所有人的疾病都是阴性，并且错误率会很低（就是发病率），但是这样的话，对于真正患病的人来说，会造成很大的损失。因此，可以定义一个损失函数，对于将患病的人判断为阴性的损失要大于将健康的人判断为阳性的损失，这样就可以得到一个更合理的决策。

### 参数估计

### 有监督的参数估计

样本所属的类别和条件以总体概率密度函数的形式已知，但描述概率密度函数的一些参数未知。例如，我们只知道样本的总体分布，但正态分布的参数未知。我们的目标是根据已知类别的样本，对总体分布进行统计判断。这种情况下的估计称为有监督的参数估计。

### 无监督的参数估计

总体概率密度函数已知，但样本所属的类别未知，需要确定概率密度函数的一些参数。这和有监督的参数估计区别在于，样本的所属类别是否已知。有两种常用的方法：最大似然估计和贝叶斯估计。

最大似然估计是将未知的参数视为定值，在获得实际观测样本的概率最大的条件下获得最佳估计值。

贝叶斯估计是将未知的参数视为一种特定分布的随机变量，